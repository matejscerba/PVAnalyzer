\chapter{Realizace}

\section{Zvolené prostředky}
\label{sec:prostredky}

Pro potřeby analýzy videa jsem použil jazyk C++ a~knihovnu OpenCV. Jelikož je analýza výpočetně náročná, dal jsem z~rychlostních důvodů přednost jazyku C++ před jazykem Python. Také mám s~jazykem C++ více zkušeností.

Tracker, který jsem zvolil pro trasování objektů je \texttt{cv\::TrackerCSRT}, jeho implementace je založena na využití Discriminative Correlation Filter with Channel and Spatial Reliability \citep{DCFwCaSR}.

Pro zobrazení parametrů v~grafické podobě jsem se rozhodl využít Matplotlib. Pro využití této knihovny není potřeba znát speciální syntaxi, základní znalosti Pythonu jsou dostačující. Jelikož je knihovna Matplotlib určena pro Python, je snadné napsat skript, který nejen vygeneruje grafy, ale také zpracuje data, která se mají zobrazit.

Program lze spustit na počítači s~Unixovým operačním systémem.




\section{Konverze souřadných systémů}
\label{sec:konverze}

Souřadné systémy snímku a~videa jsou jen posunuté o~vzájemnou pozici levého horního rohu snímku a~pozadí v~prvním snímku. Tudíž jejich konverzi reprezentuje operace posunutí.

Konverze mezi souřadným systémem videa a~prostoru je složitější. Jednotka systémů je stejná, tudíž škálování není třeba provádět. První složky bodů v~obou systémech spolu korespondují. Druhá složka bodu v~souřadném systému videa odpovídá třetí složce bodu v~prostoru. Tuto konverzi používám jen pro určení pozice kloubů těla atleta.

Je třeba zohlednit směr rozběhu atleta. Pokud běží doleva, musím převrátit hodnotu první složky. Pokud běží doprava, hodnotu první složky nechám stejnou.

Hodnotu druhé složky nastavím na $0$. Odhad pozice kloubu v~tomto směru je problematický, jelikož se atlet při skoku otáčí podél své osy, tudíž její implementaci ponechám do budoucích verzí programu. Pro její správné určení bude také potřeba zohlednit stranu, ze které je video natočeno.

Hodnotu třetí složky v~prostoru získám převrácením druhé složky bodu v~souřadném systému videa.

Výsledkem tohoto postupu je posunutý prostor, musím ho tedy posunout s~využitím pozice kotníku odrazové nohy v~momentu odrazu.

Konverzi bodu kostry $(x',y')$ v~souřadném systému videa do prostoru lze reprezentovat takto:
\begin{alignat*}{3}
&\text{Při běhu doprava:} &\qquad (x,y,z)&=(x',&0,-y')-d. \\
&\text{Při běhu doleva:} &\qquad (x,y,z)&=(-x',&0,-y')-d.
\end{alignat*}
$d$ značí pozici kotníku odrazové nohy při odrazu v~prostoru.

Pozici kotníku odrazové nohy získám až po analýze parametrů, tudíž při analýze pracuji s~posunutým prostorem. Na vliv většiny parametrů to vliv nemá, některé poté musím spočítat znovu (například výšku boků).




\section{Struktura programu}

Program se skládá z~několika tříd, UML diagram popisující strukturu je na obrázku \ref{fig:uml_schema}. Kompletní funkcionalita je přístupná skrz třídu \texttt{video\_processor} a~její metody \texttt{process\_video} a~\texttt{process\_model}. Tyto metody komunikují se zbylými částmi programu.

O~nalezení atleta se stará třída \texttt{athlete\_finder}, ta po nalezení atleta vrátí jeho pozici ve videu. K~určení atletovy pozice využívá instance třídy \texttt{athlete\_candidate}, které reprezentují postavy ve videu. Analýzu pohybu jednotlivých postav provádí jednotlivé instance třídy \texttt{movement\_analyzer} a~část zabývající se detekcí pozadí provádí pro každou postavu instance třídy \texttt{background\_tracker}.

Funkcionalitu týkající se detekcí kostry atleta zajišťuje třída \texttt{person}. Pohyb atleta zkoumá instance třídy \texttt{movement\_analyzer} ve spolupráci s~instancí třídy \texttt{background\_tracker}. O~detekci jednotlivých částí těla se stará instance třídy \texttt{parts\_detector}.

Po detekování kostry těla kovertuje detekce do modelu atletova těla třída \texttt{model}, výsledek této detekce využívá pro určení parametrů instance třídy \texttt{vault\_analyzer}, která určí hodnoty biomechanických parametrů. Parametry reprezentují specializované struktury, které dědí vlastnosti struktury \texttt{parameter}. Struktura zobrazující hierarchii parametrů je na obrázku \ref{fig:parametry}. \texttt{vault\_analyzer} také zajišťuje ukládání parametrů do souboru.

Zobrazování výstupu má za úkol třída \texttt{viewer}.

Konstanty, definice vlastních typů a~pomocné funkce jsou uloženy v~souborech \texttt{forward.cpp} a~\texttt{forward.hpp}.

\begin{figure}[h]\centering
\includegraphics[width=\textwidth]{uml_schema}
\caption{UML diagram zobrazující strukturu programu.}
\label{fig:uml_schema}
\end{figure}

%\begin{figure}[h]\centering
%\includegraphics[width=\textwidth]{parametry}
%\caption{Hierarchie implementovaných parametrů.}
%\label{fig:parametry}
%\end{figure}





\section{Vstup programu}

Programu jsou při jeho spuštění předány parametry. Parametry specifikují mód, ve kterém si uživatel přeje program spustit a~obsahují cesty k~souborům, které má program zpracovat.

O~zpracování parametrů se stará soubor \texttt{main.cpp}, který definuje vstupní bod aplikace a~volá metody třídy \texttt{video\_processor}, která zpracuje video, případně model, a~výsledek předá k~analýze.




\section{Analýza videa}

\subsection{Zpracování videa}

Zpracování videa má na starosti třída \texttt{video\_processor}. 

Video načtu s~použitím třídy \texttt{cv\::VideoCapture}. Z~videa získám hodnotu frekvence snímků a~jednotlivé snímky videa uložím při průchodu do vektoru $3$-rozměrných matic \texttt{cv\::Mat}, které reprezentují snímky videa.

Z~důvodu časové náročnosti videí s~velikým rozlišením zmenším každý snímek metodou \texttt{cv\::resize}. Výsledný snímek videa má rozlišení 720p. Při zpracování videa na šířku je výška videa 720\,\rm pixelů, šířka se změní, aby byl poměr stran snímku zachován. Při zpracování videa na výšku je šířka výsledného snímku 720\,\rm pixelů, výška se změní v~odpovídajícím poměru.

Vzorce pro změnu velikosti snímku videa s~rozlišením $x'\times y'$ na výsledné rozlišení $x\times y$, reprezentující 720p jsou následující:
\begin{alignat*}{3}
&\text{Na výšku:}   &\qquad (x, y) &= (720 \cdot x' / y',   &720) \\
&\text{Na šířku:}   &\qquad (x, y) &= (720,                 &720 \cdot y' / x')
\end{alignat*}
První složka udává šířku snímku, druhá výšku.



\subsection{Nalezení atleta}

Nalezení atleta jsem implementoval dvěma způsoby - manuálním a~automatickým. O~nalezení atleta se stará třída \texttt{athlete\_finder}.

\subsubsection{Manuální způsob}

Tímto způsobem určí uživatel pozici atleta ve snímku. Vybere snímek, ve kterém je atlet v~záběru a~následně ho uzavře do ohraničujícího rámečku. Tuto funkcionalitu v~grafickém rozhraní nabízí metoda \texttt{cv\::selectROI}.


\subsubsection{Automatický způsob}

Abych nalezl atleta automaticky, procházím snímky videa postupně, udržuji si seznam postav ve videu a~atleta ve videu. Postavy reprezentuje \texttt{std\::list}, jehož prvky jsou instance třídy \texttt{athlete\_finder\::athlete\_candidate}. Pro \texttt{std\::list} jsem se rozhodl, jelikož se počet postav ve videu často mění a~při této operaci není potřeba \texttt{std\::list} realokovat. Atleta ve videu reprezentuje instance \texttt{std\::optional<person>}, její hodnota není validní, dokud nenaleznu atleta.

Dokud nenaleznu atleta, opakuji při zpracování každého snímku následující postup.

Vyfiltruji seznam postav ve videu, abych v~seznamu nechal jen postavy, které mohou reprezentovat atleta. Mezi těmito postavami se pokusím najít atleta. Pokud ho najdu, vytvořím instanci třídy \texttt{person} na základě snímku, ve kterém jsem ho poprvé detekoval, a~jeho pozice v~něm. Pokud je seznam postav prázdný a~zatím se mi nepodařilo najít atleta, spustím detekci postav v~právě zpracovávaném snímku a~detekované postavy uložím do seznamu postav.

Postavy, jejichž trasování neselhalo, jsou celé uvnitř snímku [MOŽNÁ ÚPRAVA] a~pohybují se, mohou reprezentovat atleta, proto je ze seznamu postav nesmažu. Pokud neuplynulo $0.3$\,\rm s od první detekce postavy, považuji ji za pohybující se. Po uplynutí této doby se musela od momentu první detekce pohnout v~horizontálním směru alespoň o~šířku jejího ohraničujícího rámečku, abych ji považoval za pohybující se a~nechal ji mezi kandidáty na atleta. Pozici postavy určuje střed jejího ohraničujícího rámečku. Pohyb postav zkoumá třída \texttt{movement\_analyzer}.

Za atleta zvolím postavu, pro kterou je určen směr pohybu. Směr pohybu určí třída \texttt{movement\_analyzer} jakmile se postava pohne alespoň o~šířku jejího ohraničujícího rámečku v~horizontálním směru.

Oraničující rámečky postav vykreslím do snímku a~tyto snímky vrátím pro následné vytvoření videa.

\paragraph{Detekce postav ve snímku}

Detekci postav ve snímku provádí instance třídy \texttt{cv\::HOGDescriptor} pomocí knihovního SVM detektoru, který vrátí metoda \texttt{cv\::HOGDescriptor\::getDefaultPeopleDetector}. Ohraničující rámečky postav ve videu získám metodou \texttt{cv\::HOGDescriptor\::detectMultiScale}. Parametry této metody jsou
\begin{itemize}
\item právě zpracovávaný snímek,
\item detekované ohraničující rámečky,
\item práh detekce,
\item posun okna,
\item obal okna,
\item škálování,
\item konečný práh a
\item použití seskupovacího algoritmu.
\end{itemize}

\emph{Práh detekce} určuje vzdálenost klasifikační roviny SVM detektoru a~vlastností právě zpracovávaného okna. Hodnotu tohoto parametru jsem nechal výchozí - tedy $0$.

\emph{Posun okna} určuje velikost kroku mezi okny pro detekci postav ve snímku. Velikost tohoto kroku jsem nastavil na $(4,4)$\,\rm pixely.

\emph{Obal okna} je počet pixelů okolo okna v~obou směrech, které detektor zahrnuje do detekce. Velikost obalu jsem zvolil $(16,16)$.

\emph{Škálování} udává koeficient, kterým se zmenšuje vstupní snímek. Jelikož detekuji různě veliké postavy a~okno pro detekci má pevnou velikost, musím měnit velikost snímku a~detekci spouštět na různých velikostech. Snímek tedy po každé detekci zmenším daným koeficientem, jehož hodnotu jsem nastavil na $1.05$.

\emph{Konečný práh} není v~knihovně dostatečně okomentován, proto jsem ponechal výchozí hodnotu $2$.

\emph{Použití seskupovacího algoritmu} udává, zda se před vrácením ohraničujících rámečků postav má použít algoritmus pro jejich seskupení. Tento algoritmus nefungoval příliš dobře, proto seskupení rámečků implementuji sám. Používám modifikaci algoritmu non-maxima suppression \citep{NMS}. Algoritmus jsem implementoval stejně, jen jsem se rozhodl seřadit rámečky podle velikosti, nikoliv podle pozice jejich spodních stran. Důvodem pro tuto změnu byla skutečnost, že metoda detekovala postavu jen na části atletova těla, tudíž pro určení výsledné detekce dávám přednost větším rámečkům. [OBRÁZEK]

\paragraph{Analýza pohybu postav}

O~analýzu pohybu postav se stará třída \texttt{movement\_analyzer}, stejná třída se stará i o~pohyb atleta, jehož trasování je modifikované, tudíž je analýza pohybu blíže popsaná v~sekci \ref{ssec:detekce}.

Při analýze atletova pohybu předávám třídě \texttt{movement\_analyzer} vektor všech rámečků mřížky. Postavy při hledání atleta mřížku nemají, tudíž předám jednoprvkový vektor obsahující ohraničující rámeček postavy.



\subsection{Detekce kostry}
\label{ssec:detekce}

Jelikož může být postav ve videu více, bylo potřeba pro přesnost detekce kostry atleta ze snímku vyříznout okno, ve kterém se atlet nachází. Pozici tohoto okna určuji trasováním atleta. Detekci kostry atleta zajišťuje instance třídy \texttt{person}, která reprezentuje atleta.

Video se zpracovává postupným procházením snímků videa. V~každém snímku určím pozici atletova těla a~následně detekuji klouby kostry. Do snímku zakreslím detekce a~po průchodu celého videa snímky se zakreslenými detekcemi vrátím.

Pozice detekovaných kloubů atletova těla v~jednotlivých snímcích udržuje instance třídy \texttt{person}. Posun snímků pro převod těchto pozic do souřadného systému videa obstarává třída \texttt{movement\_analyzer}.


\subsubsection{Trasování atleta}

Jak jsem již popisoval v~sekci \ref{ssec:ndetekce}, bylo potřeba trasování atleta modifikovat, aby byla kvalita trasování při skoku dostatečná. Rozhodl jsem se pro rozdělení původního ohraničujícího rámečku atleta na mřížku $3\times 3$ menších rámečků. Chtěl jsem jedním z~menších rámečků pokrýt střed ohraničujícího rámečku, proto jsem se rozhodl pro tento počet. Každý rámeček v~mřížce trasuji samostatně, trackery jednotlicých rámečků jsou uloženy v~1D vektoru. Kvůli analýze pohybu rámečků při aktualizaci mřížky ukládám pozice rámečků do vektoru, který pro každý snímek obsahuje vektor pozic rámečků v~daném snímku.

V~prvním snímku, kde jsem detekoval atleta inicializuji tracker pro každý rámeček mřížky.

Ihned po inicializaci a v~následujících snímcích určím pozici jednotlivých rámečků. Pokud trasování všech rámečků mřížky selže, ukončím trasování atleta a v~následujících snímcích kostru nedetekuji.

Vzhledem k~tomu, že atleta trasuji po částech se může stát, že některé trackery začnou trasovat pozadí videa. Abych je přesunul na správné místo, zkoumám pohyb jednotlivých trackerů za poslední $2$\,\rm snímky.

Vyberu rámeček, jehož pozice se za poslední $2$\,\rm snímky nejvíce změnila. Kontroluji, aby horizontální směr odpovídal směru rozběhu atleta. K~tomuto rámečku přesunu mřížku, aby v~ní byl nejvíce se pohybující se rámeček na původním místě. Musím také zajistit, aby byla mřížka uvnitř snímku. Mřížku opět rozdělím na menší rámečky a~inicializuji v~ní trackery, které atleta ztratily.

Tyto trackery určím tak, že posun jejich rámečků je menší než $1/4$\,\rm posunu nejvíce se pohybujícího rámečku. Při skoku atlet švihá nohou směrem dopředu, pohyb této nohy vůči pozadí je přibližně dvojnásobný vůči pohybu trupu, tudíž jsem musel zvolit menší hodnotu než $1/2$, abych zamezil přesunu validních trackerů z~trupu na nohu.

Po aktualizaci rámečků je $2$\,\rm snímky neaktualizuji, aby do jejich pohybu nebyla započítána jejich aktualizace.

Atletova pozice se v~průběhu videa mění, snažil jsem se implementovat i~změnu velikosti mřížky podle velikosti těla atleta, ale přesnost trasování se zhoršila, proto škálování mřížky neprovádím.


\subsubsection{Analýza pohybu atleta}

Pro určení pozice atleta v~souřadném systému videa využívám třídu \texttt{movement\_analyzer} a~\texttt{background\_tracker}. Tato třída analyzuje také pohyb postav, každá instance analyzuje pohyb jediné postavy.

Atlet je ve snímku reprezentován několika rámečky, postava jedním, ale ten zabalím do vektoru a~následný postup je pro oba případy stejný. Pozicí postavy ve snímku rozumím střed nejmenšího obdélníku, do něhož lze rámečky uzavřít. Rámečky ve snímku, snímek a~číslo snímku dostane analyzátor pobyhu na vstupu.

V~prvním snímku, ve kterém chci určit pozici atleta, inicializuji tracker pozadí. Část pozadí, kterou budu trasovat uzavřu do ohraničujícího rámečku, který má velikost $x/4\times y/2$, kde $x$ je šířka snímku, $y$ výška. Tento rámeček umístím k~levé nebo pravé straně snímku, podle toho na jaké straně je průnik atleta a~pozadí menší. Přednost má levá strana. Rámeček umístím tak, aby nad ním i~pod ním bylo stejně místa. Tím se vyvaruji trasování jednobarevného nebe, případně tartanu, pokud bych pozadí umístil nahoru, případně dolů.

Při zpracování každého snímku zjistím pozici levého horního rohu snímku v~souřadném systému videa, díky čemuž snadno určím pozici libovolného objektu ve snímku.

Pozice pozadí ve videu je $d_0=b_0-p_0$, $b_0$ udává pozici středu pozadí v~tomtéž snímku, $p_0$ je pozice atleta v~prvním snímku, ve kterém ho detekuji. Pozice $t_0$ levého horního rohu prvního snímku je rovna $-p_0=d_0-b_0$.

Při analýze dalšího snímku znám pozici atleta $p_1$ ve snímku. S~využitím trackeru určím pozici pozadí $b_1$ ve snímku a~jeho pozici $d_1=d_0$ ve videu. Ze znalosti pozice pozadí získám pozici levého horního rohu snímku $t_1=d_1-b_1$. Takto získám pozici levého horního rohu každého snímku.

Jelikož se záběr kamery pohybuje, je potřeba pozadí aktualizovat, jakmile se dostane mimo záběr. S~touto aktualizací musím aktualizovat pozici nového pozadí ve videu. Mám tedy pozadí, které se dostalo mimo záběr. Jeho pozice ve videu je $d_i$, pozice ve snímku $b_i$. Inicializuji nové pozadí s~pozicí $n_i$ ve snímku. Pozice nového pozadí ve videu se určí jako $d_i+n_i-b_i$. Dále pracuji s~touto hodnotou místo $d_i$ a~novým pozadím videa. [OBRÁZEK]

Pozadí přesunu také jakmile do oblasti pozadí vběhne atlet. Pokud pozadí bez průniku s~atletem nelze vytvořit, nezacyklím se, jen budu v~každém snímku vytvářet nové pozadí, aby byl průnik minimální.

Podle pohybu atleta ve videu také určím směr jeho rozběhu pro následný převod kostry do 3D modelu. Směr rozběhu určím, jakmile se pozice atleta změní alespoň o~šířku jeho těla od první pozice, kde jsem atleta detekoval.


\subsubsection{Detekce kloubů těla}

Klouby těla jsou určeny databází MPII Human Pose dataset \citep{MPIIHPE}. Jedná se o~$16$ bodů těla, ale posledním je pozadí, které mohu ignorovat. Používám tedy jen prvních $15$ bodů těla. Jedná se o
\begin{enumerate}
\setcounter{enumi}{-1}
\item hlavu,
\item krk,
\item pravé rameno,
\item pravý loket,
\item pravé zápěstí,
\item levé rameno,
\item levý loket,
\item levé zápěstí,
\item pravou kyčel,
\item pravé koleno,
\item pravý kostník,
\item levou kyčel,
\item levé koleno,
\item levý kotník a
\item hrudník.
\end{enumerate}

O~detekci kloubů těla se stará třída \texttt{parts\_detector}. Ta dostane pro detekci snímek, rámečky atletova těla v~něm a~maximální vzdálenost, o~kterou může posunout střed okna od středu atletova těla, což je střed nejmenšího rámečku, do něhož se vejdou rámečky atletova těla. Maximální vzdálenost je určena průměrnou vzdáleností dvojic středů rámečků atleta.

Detektor si pamatuje poslední velikost kostry, posun středu okna a~úhel naklonění trupu. Detekci zkouší na natočení proti poslednímu známemu úhlu trupu a~následnému natočení o~$20$\,\rm stupňů oběma směry. Tyto detekce probíhají postupně a~vybere se ta, která detekuje nejvíce kloubů těla. Pokud nějaká detekce uspěje na $100$\,\rm \%, další se nezkouší.

Úhel naklonění trupu určuji jako úhel mezi úsečkou spojující střed kyčlí a~hlavu a~vertikálou, která prochází středem kyčlí. Úhel reprezentuje míru natočení trupu oproti vzpřímené pozici po směru hodinových ručiček. [OBRÁZEK] Hodnoty jsou v~rozmezí $[-180,180]$\,\rm stupňů. Metoda \texttt{cv\::rotate} otáčí snímek o~úhel proti směru hodinových ručiče, tudíž bude ve otočeném snímku atletův trup vzpřímený, když mu předám nezměněnou hodnotu úhlu naklonění trupu.

Výpočet úhlu naklonění trupu provádím následující metodou:
\begin{code}[fontsize=\footnotesize]
std::optional<double> get_vertical_tilt_angle(
    const frame_point &a,
    const frame_point &b) noexcept {
        if (a && b) {
            cv::Point2d v1(0, - 1); // Point straight up.
            cv::Point2d v2 = *b - *a;
            double dot = v1.x * v2.x + v1.y * v2.y;
            double val = dot / (cv::norm(v1) * cv::norm(v2));
            double mult = 1;
            if (v2.x != 0)
                mult = v2.x / std::abs(v2.x);
            return mult * std::acos(val) * 180.0 / M_PI;
        }
        return std::nullopt;
}
\end{code}
Prvním argumentem je pozice středu kyčlí, druhým pozice hlavy atleta. Pro výpočet využívám vlastnosti skalárního součinu, díky kterému lze určit úhel mezi vektory. Při výpočtu vycházím ze vzorce $\langle u,v\rangle=\lVert u\rVert\cdot\lVert v\rVert\cdot\cos\alpha$, kde $\alpha$ je úhel, který vektory svírají.

Pro detekci kloubů těla nejprve vyberu rámeček okna pro detekci. Jeho střed získám ze středu rámečků atleta a~posunu středu z~minulého snímku. Rámečky atleta aktualizuji každé $2$\,\rm snímky, tudíž jejich posunutí při aktualizaci není velké. [OBRÁZEK] Velikost jeho strany určím z~velikosti dosud největší detekované kostry, kterou zvětším koeficientem $1.3$. Pokud je velikost kostry dosud neznámá, zvětším $1.3$\,\rm krát nejmenší rámeček obsahující rámečky atletova těla. Škálování rámečků provádím tak, abych zachoval jejich střed a~aby se vešly do snímku.

Následně kolem středu zvoleného rámečku okna otočím snímek proti poslednímu známému naklonění trupu, k~tomuto úhlu případně přičtu úhel dalšího naklonění, pokud se detekce nepodaří napoprvé. K~natočení snímku využiji metodu \texttt{cv\::rotate}. Z~natočeného snímku vyříznu část, která je určena oknem. Střed okna zůstal po rotaci na stejném místě, takže získám jen natočené okno. [OBRÁZEK] Toto okno zmenším na rozlišení, jehož menší strana má $150$\,\rm px, aby detekce probíhala rychleji. Toto zmenšení nemá příliš velký vliv na přesnost detekcí, ale značný vliv na rychlost analýzy videa [ODKAZ na experiment].

Zmenšené okno předám jako vstup konvoluční sítě a~spustím detekci. Z~výsledku detekce extrahuji klouby těla do nezmenšeného okna, ty podle jeho pozice a~naklonění posunu na správnou pozici do snímku.

Nakonec aktualizuji velikost dosud největší detekované kostry, pokud detekuji všechny části těla a~tato kostra je největší. Také aktualizuji posun středu okna oproti středu rámečku ohraničujícího atleta. Tento posun zmenším, pokud je větší, než maximální vzdálenost. Jako poslední aktualizuji úhel naklonění trupu, pokud se od posledního známého liší o~míň, než $30$\,\rm stupňů. Tento úhel určuje střed kyčlí a~hlava atleta vůči vertikále, pokud byly tyto části těla v~předchozím snímku detekovány, jinak úhel neaktualizuji.

\paragraph{Síť}

K~detekci kloubů těla používám konvoluční síť, která je implementovaná ve frameworku Caffe \citep{Caffe}. Tuto síť načtu ze souborů metodou \texttt{cv\::dnn\::readNet}. Váhy sítě a~její parametry jsem použil z~projektu OpenPose \citep{OpenPose}. Vstupem této sítě může být libovolně velký obrázek. Výstupem sítě je $4$-dimenzionální matice \texttt{cv\::Mat}, dimenze popisují
\begin{itemize}
\item číslo snímku,
\item číslo výstupní vlastnosti,
\item výšku výstupu a
\item šířku výstupu.
\end{itemize}

\paragraph{Extrakce kloubů z~výstupu}

Číslo snímku je irelevantní, jelikož předávám síti vždy jen jeden snímek. Výstupních vlastností je pro MPII model $44$, ale používám jen prvních $15$, které reprezentují klouby těla. Pro lepší přesnost detekce by bylo vhodné využít i~zbylé vlastnosti. Z~výstupu dostanu matici pravděpodobností kloubu $n$ konstruktorem \texttt{cv\::Mat}, kterému dám výšku, šířku, typ prvků a~ukazatel na výslednou matici, který dostanu z~výstupu sítě. Ze získané matice vyberu pozici prvku, který má maximální pravděpodobnost. Pokud je tato pravděpodobnost větší než $0.1$, určím přeškálováním pozice bodu ve výstupu poměrem velikosti nezmenšeného vstupu a~výstupu sítě pozici bodu ve vstupu. Výslednou pozici určím výpočtem $(x,y)=(x_{out}\cdot w_{in}/w_{out}, y_{out}\cdot h_{in}/h_{out})$. $(x_{out},y_{out})$ je pozice na výstupu, $(w_{in},h_{in})$ velikost vstupu a~$(w_{out},h_{out})$ velikost výstupu.

Podle pozice a~natočení okna ve snímku určím pozici výsledných bodů ve snímku. Bod posunu o~levý horní roh okna, tím získám pozici bodu v~otočeném snímku. Otočením bodu podle středu okna o~úhel natočení okna zpět získám pozici bodu v~nerotovaném snímku. Pro otočení bodu využiji metodu \texttt{cv\::transform}. [OBRÁZEK]

Pozice kloubů reprezentuji jako instance \texttt{cv\::optional<cv\::Point2d>}, tedy pozice kloubů, které se mi nepodaří nadetekovat, nejsou definované.



\subsection{Konverze kostry do 3D modelu}

O~převod kostry do 3D modelu se stará konstruktor třídy \texttt{model}. Konstruktor dostane instanci třídy \texttt{person}, která reprezentuje atleta a~cestu ke zpracovanému videu.

Nejprve se převedou klouby kostry do 3D, aby se daly body sčítat. Výsledkem konverze bodu $(x,y)$ je bod $(x,0,y)$. Stejná operace se provede s~pozicemi levého horního rohu jednotlivých snímků.

Následně se díky těmto výsledkům určí reálná pozice bodů. Mám tedy kloub kostry $(x,y,z)$ a~posun snímku $(x',y',z')$. Výsledná pozice je $(x+x',y+y',z+z')$, pokud atlet běží doprava, $(-x-x',y+y',z+z')$ pokud atlet běží doleva.

Posunutí počátku systému do pozice kotníku odrazové nohy v~momentu odrazu se provádí po analýze parametrů odečtením této hodnoty.



\subsection{Analýza parametrů}

Pro analýzu parametrů skoku používám pozice kloubů těla v~každém snímku. Tyto hodnoy mám uložené ve vektoru vektorů, jehož prvky jsou instance \texttt{std\::optional<cv\::Point3d>}. První dimenze určuje číslo snímku, druhá číslo kloubu. I~když atleta nedetekuji v~celém videu, mám pro každý snímek uloženy pozice kloubů. Pokud jsem v~daném snímku kloub nedetkoval, je jedo hodnota nedefinovaná (\texttt{std\::nullopt}).

Detekce kloubů těla není úplně přesná, často při detekci prohodí levá a~pravá noha, tuto chybu je potřeba brát při analýze parametrů v~potaz. [GRAF levého kotníku, pravého kotníku a~nižšího kotníku]

O~analýzu parametrů se stará třída \texttt{vault\_analyzer} a~struktury reprezentující jednotlivé parametry, pro analýzu používám souřadný systém 3D prostoru.


\subsubsection{Důležité momenty skoku}

\paragraph{Start}

Start rozběhu je snímek, ve kterém se začne pohybovat atletův kotník. Postupně zkoumám pozice kotníků ve všech snímcích videa a~udržuji si předešlou pozici levého a~pravého kotníku. Jakmile se pozice levého nebo pravého kotníku změní o~více než $1$\,\rm pixel, ukončím procházení a~vrátím číslo snímku, ve kterém pohyb začal - jedná se předposlední snímek, který jsem zkoumal. Změna pozice kotníků, kterou určuji při zpracování prvního snímku není definovaná, tudíž zpracuji vždy alespoň $2$\,\rm snímky a~výsledné číslo snímku je validní.

O~určení momentu startu rozběhu se stará metoda \texttt{vault\_analyzer\::find\_start}:
\begin{code}[fontsize=\footnotesize]
std::optional<std::size_t> find_start(const model_video_points &points)
noexcept {
    std::size_t index = 0;
    model_point left = std::nullopt;
    model_point right = std::nullopt;
    for (const auto &body : points) {
        std::optional<double> dist =
            distance(body[body_part::l_ankle], left);
        if (dist && *dist > 1) break;
        dist = distance(body[body_part::r_ankle], right);
        if (dist && *dist > 1) break;
        left = body[body_part::l_ankle];
        right = body[body_part::r_ankle];
        ++index;
    }
    if (index && index != points.size())
        return index - 1;
    return std::nullopt;
}
\end{code}
Funkce \texttt{distance} funguje stejně, jako metoda \texttt{cv\::norm} aplikovaná na rozdíl argumentů, pokud jsou oba argumenty validní, jinak vrátí \texttt{std\::nullopt}.

\paragraph{Odraz}

Moment odrazu je snímek, ve kterém dochází k~odrazu od země při posledním detekovaném kroku. Popis detekce kroků popisuji v~následující sekci.

\paragraph{Kulminace}

Moment kulminace nad laťkou je určen snímkem, ve kterém je pozice středu kyčlí nejvýš v~celém videu.


\subsubsection{Doba trvání jednotlivých kroků}

Pro určení doby trvání kroků je potřeba určit specifický moment každého kroku. Zvolil jsem určení momentu odražení od země jednotlivých kroků, tato implementace mi pomohla s~detekcí momentu odrazu.

Jelikož si nemohu být jistý pozicí levé a~pravé nohy, musím zkoumat pozici nižšího kotníku. Postupně procházím pozice nižšího kotníku v~jednotlivých snímcích videa. Určím momenty, ve kterých nižší kotník opouští lokální minimum.

Jelikož detekce nemusí být vždy přesná, musím určit práh, jehož překonání znamená verikální posunutí kloubu kostry. Velikost tohoto prahu musí záviset na velikosti těla atleta a~frekvenci snímků videa. Velikost prahu určuji takto: $x\cdot s/fps$, kde $s$ je vzdálenost dvou nejvzdálenějších kloubů těla atleta, $fps$ frekvence snímků videa a~$x$ vhodná hodnota. Po analýze vertikálních pohybů nižšího kotníku v~momentech odrazů jednotlivých kroků několika videí, jejichž frekvence snímků byla $60$\,\rm fps, jsem hodnotu $x$ nastavil na $0.023\cdot 60=1.38$. Zvolil jsem nejmenší vertikální posun v~momentech odrazů jednotlivých kroků v~analyzovaných videích. Jednalo se o~videa \texttt{1.MOV}, \texttt{8.MOV} a~\texttt{12.MOV}.

Možným vylepšením by bylo zkoumání levé a~pravé nohy a~jejich vzájemné pozice - která je vepředu a~která vzadu - ale jelikož není detekce levé a~pravé nohy občas správná, musel jsem se rozhodnout pro výše popsanou implementaci.

Pro přesnost určení kroků je potřeba vyfiltrovat snímky, ve kterých nedochází ke kroku, příkladem je chvíle po odrazu, při níž atlet švihá odrazovou nohou dopředu. Odrazová noha se tedy po odrazu pohybuje vzhůru a~následně dolů (při švihu), což může být z~hlediska algoritmu vnímáno jako krok. [OBRÁZEK]

Budu postupně procházet snímky, ve kterých nižší kotník opouští lokální minimum, označím je jako snímky odrazů. Mezi následujícími snímky odrazů najdu nejvyšší pozici nižšího kotníku. Následující snímek odrazu označím za krok jen v~případě, že se v~něm nižší kotník nachází pod průměrem výšky nalezeného maxima nižšího kotníku a~výšky nižšího kotníku v~momentu předešlého odrazu. První snímek odrazu ve výsledném seznamu nechám. [OBRÁZEK]

Abych nedetekoval kroky po provedení skoku, ukončím filtraci (a~další kroky do výsledku nepřidám) jakmile narazím na snímek, který reprezentuje odraz při kroku a~nižší kotník se v~něm nachází výš, než je nejvyšší pozice nižšího kotníku mezi prvním a~druhým krokem. [OBRÁZEK]

Podle frekvence snímků videa a~vyfiltrovaných čísel snímků, v~nichž dochází k~odrazu při krocích, určím dobu trvání kroků. Doba trvání $i$-tého kroku je tedy $d_i=(k_{i+1}-k_i)\cdot fps$, $k_i$ je číslo snímku $i$-tého odrazu kroku a~$fps$ je frekvence snímků videa.


\subsubsection{Ztráta rychlosti ramen a~boků}

Pro výpočet ztráty horizontální rychlosti ramen a~boků vuyžívám střed ramen a~kyčlí atletova těla. Nejprve určím pozici středu boků $0.1$\,\rm s před momentem odrazu, při odrazu a~$0.1$\,\rm s po momentu odrazu.

Pokud byly úspěšné detekce ve všech popsaných momentech a~mám jistotu, že nebudu dělit nulou, spočítám výslednou ztrátu rychlosti vzorcem $l=(1-(a-d)/(d-b))\cdot100$, kde $a$ je hodnota první složky pozice zkoumané části těla $0.1$\,\rm s po odrazu, $d$ určuje stejnou hodnotu v~momentu odrazu a~$b$ před odrazem. Výslednou ztrátu určuji v~procentech.

Pokud hodnotu výrazu nelze spočítat, má tento parametr nedefinovanou hodnotu.


\subsubsection{Výška boků}

V~průběhu celého videa určuji výšku boků. Pro každý snímek uložím hodnotu průměru výšky levé a~pravé kyčle. Pokud se ve snímku podařilo detekovat jen jednu kyčli, uložím výšku detekované, pokud se nepodaří detekovat ani jednu kyčel ve snímku, je hodnota výšky boků v~tomto snímku nedefinovaná.


\subsubsection{Úhel odrazu}

Úhel odrazu určuji jako rozdíl úhlu pohybu na začátku skoku a~úhlu pohybu na konci rozběhu. Úhly pohybu udávají úhel mezi $x$-ovou osou a~směrem pohybu středu kyčlí atleta.

Pro výpočet úhlu odrazu získám pozici středu kyčlí $0.1$\,\rm s před momentem odrazu, při odrazu a~$0.1$\,\rm s po odrazu. Z~pozice kyčlí při odrazu a~po něm určím úhel, pod kterým se pohybuje atlet při skoku. Na základě pozice kyčlí při odrazu a~před ním vypočítám úhel pohybu před odrazem.

Kladná hodnota úhlu odrazu znamená odraz vzhůru, záporná odraz dolů. Hodnoty jsou v~intervalu $[-180,180]$\,\rm stupňů.


\subsubsection{Úhel došlapu jednotlivých kroků}

Algoritmem, kterým získávám momenty došlapů pro výpočet oporové fáze kroků, získám momenty došlapů všech kroků. V~nich určím úhel mezi vertikálou a~úsečkou, kterou určuje kotník a~kyčel došlapující nohy.

Jedná se o~míru došlapu nohy před kyčel, při došlapu před kyčel je tedy hodnota kladná, při došlapu za kyčel je hodnota záporná. Hodnoty se pohybují mezi $-180$ a~$180$\,\rm stupni.


\subsubsection{Náklon trupu}

Náklon trupu je úhel mezi vertikálou a~úsečkou, kterou určuje pozice středu kyčlí a~pozice hlavy. Tento úhel vypočítám pro každý snímek videa.

Úhel určuji stejně, jako v~případě detekce kostry (sekce \ref{ssec:detekce}), jen se jedná o~úhel v~trojrozměrném prostoru. Jedná se o~míru naklonění, jejíž hodnota je kladná, pokud je atlet v~předklonu a~záporná, pokud je v~záklonu. Směr rozběhu je ve směru rostoucí $x$-ové souřadnice.

Hodnota naklonění trupu se pohybuje v~rozmezí $-180$ až $180$\,\rm stupňů.



\section{Analýza modelu}

O~načtení modelu ze souboru se stará třída \texttt{model}, podle uložených pozic kloubů kostry vůči levému hornímu rohu snímku a~posunu snímku ve videu se klouby převedou do 3D modelu. Tento postup je stejný jako při převodu detekované kostry do 3D modelu. Tento model je narozdíl od konverze z~detekované kostry posunut, aby byl počátek systému v~místě kotníku odrazové nohy v~momentu odrazu.

Pro následnou analýzu parametrů se využívá model ve 3D souřadném systému stejným způsobem, jako při analýze videa.



\section{Výstup programu}

\subsection{Uložení výstupu}

Výstup ukládám do textových souborů, které jsou uloženy ve složce \texttt{outputs/\allowbreak name/}, kde \texttt{name} je název zpracovávaného videa (bez cesty a~přípony). Parametry ukládám do souboru \texttt{parameters.csv}, model do souboru \texttt{model.txt}.

Uložení parametrů provádí třída \texttt{vault\_analyzer}, uložení modelu má na starosti třída \texttt{model}. Pro vypisování hodnot do souboru používám \texttt{std\::ofstream}.

Struktura těchto souborů je popsaný v~sekci \ref{ssec:ulozeni}.

Kromě těchto textových souborů generuje program trojici videí, kterou uloží do stejné složky jako textové soubory.

Prvním z~nich je video bez detekcí, obsahuje původní snímky videa, která program zmenšil před analýzou. Název tohoto videa je \texttt{raw.avi}.

Druhé video se generuje jen v~případě, že uživatel zvolí automatickou detekci atleta, obsahuje postavy, které program v~každém videu bral v~potaz při hledání atleta. Jedná se o~video \texttt{found.avi}.

Třetí video obsahuje zakreslenou kostru, rámečky těla atleta a~pozici trasovaného pozadí. Toto video se zapíše do souboru \texttt{detections.avi}.



\subsection{Zobrazení výstupu uživateli}

O~funkcionalitu zobrazení výstupu uživateli se stará třída \texttt{viewer}. Ta nejprve otevře prohlížeč snímků videa a~následně zobrazí grafy obsahující hodnoty parametrů.


\subsubsection{Prohlížeč snímků}

Prohlížeč snímků spustím zavoláním metody \texttt{viewer::show}. Jejími parametry jsou snímky videa s~detekcemi, bez detekcí a~instance třídy \texttt{vault\_analyzer}, která analyzovala atletův pohyb.

Prohlížeč si udržuje číslo právě zobrazovaného snímku, při jeho změně kontroluje, aby se jeho hodnota nedostala mimo hodnoty, kterými lze přistupovat k~jednotlivým snímkům.

V~nekonečné smyčce provádí program následující kroky:

Snímek zobrazím metodou \texttt{cv\::imshow}, která vytvoří okno a v~něm zobrazí snímek podle čísla právě zobrazovaného snímku.

Spolu se zobrazením snímku vypíše program do konzole číslo snímku, dobu snímku vůči odrazu a~hodnoty parametrů, které s~daným snímkem souvisí. [TABULKA]

Následně se čeká na vstup uživatele s~využitím metody \texttt{cv\::waitKey}. Tato metoda vrací kód klávesy, kterou uživatel stiskl a~čeká na vstup uživatel neomezeně dlouhou dobu.

Levou a~pravou šipkou se uživatel pohybuje mezi snímky videa dopředu, případně dozadu, mezerníkem uživatel zobrazí a~opět skryje zakreslené detekce kostry atletova těla. Stiskem klávesy \texttt{esc} se zobrazí grafy s~hodnotami parametrů a~ukončí se prohlížení snímků videa přerušením smyčky.


\subsubsection{Grafická reprezentace parametrů}

Zobrazení parametrů v~grafické podobě zajišťuje skript \texttt{plot\_parameters.py}, který načte hodnoty parametrů ze souboru, který se vygeneroval při analýze parametrů.

Skript se spouští přímo z~kódu jazyka C++, což zajišťuje API pro použití Pythonu prostředky, kterými disponuje jazyk C \citep{PythonC}. O~spouštění se stará třída \texttt{viewer}.

Kód, který spouští skript pro zanesení parametrů do grafů vypadá následovně:
\begin{code}[fontsize=\footnotesize]
void show_parameters() const noexcept {
    Py_Initialize();

    FILE *file = fopen("plot_parameters.py", "r");
    if(file) {
        wchar_t *argv[3] = {
            Py_DecodeLocale("plot_parameters.py", NULL),
            Py_DecodeLocale("--file", NULL),
            Py_DecodeLocale(params_filename.c_str(), NULL)
        };
        PySys_SetArgv(3, argv);
        PyRun_SimpleFile(file, "plot_parameters.py");
        fclose(file);
    }

    Py_Finalize();
}
\end{code}






































